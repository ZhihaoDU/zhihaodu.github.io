
<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>About | [“Welcome to Zhihao Du（杜志浩）’s homepage.”]</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="About" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="https://zhihaodu.github.io/" />
<meta property="og:url" content="https://zhihaodu.github.io/" />
<meta property="og:site_name" content="[“Welcome to Zhihao Du（杜志浩）’s homepage.”]" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="About" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","headline":"About","name":"[“Welcome to Zhihao Du（杜志浩）’s homepage.”]","url":"https://zhihaodu.github.io/"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=b3e4a4daa47f83a7474c6268eaa95beeb8e0e9c4">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <div class="container-lg px-3 my-5 markdown-body">
      
      <h1><a href="https://zhihaodu.github.io/">Welcome to Zhihao Du（杜志浩）’s homepage.</a></h1>
      

      <h2 id="about">About（关于）</h2>

<p>I'm a senior researcher of Speech Lab, DAMO academy, Alibaba group. 
  I recieved the Ph.D. degree with the School of Computer Science and Technology at Harbin Institute of Technology under the supervision of Jiqing Han, in 2021. 
  I received the B.E. degree in software engineering from the College of Software of Inner Mongolia University under the supervision of Xueliang Zhang, in 2015. 
  My research interests include multi-talker speech processing, speech separation, speech synthesis, and deep learning. 
  Last, but certainly not least, I'd like to thanks my wonderful wife for her understanding and supports.</p>

<h2 id="publications">Publications（出版物）</h2>

<p>(Note: Most of my papers can be found on arxiv.)</p>

<h3 id="journal--papers">Journal  Papers（期刊论文）</h3>

<ol>
  <li><strong><u>Zhihao Du</u></strong>, Xueliang Zhang, Jiqing Han. A joint framework of denoising autoencoder and generative vocoder for monaural speech enhancement. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2020. <a href="https://zhihaodu.github.io/dagv_demo/">View Demos</a></li>
</ol>

<h3 id="conference-papers">Conference Papers（会议论文）</h3>

<ol>
  <li>Yue Gu, <strong><u>Zhihao Du</u></strong>, Shiliang Zhang, Qian Chen, Jiqing Han, "Personality-aware Training based Speaker Adaptation for End-to-end Speech Recognition, INTERSPEECH 2023</li>
  <li>Mohan Shi, <strong><u>Zhihao Du</u></strong>, Qian Chen, Fan Yu, Yangze Li, Shiliang Zhang, Jie Zhang, Lirong Dai, "CASA-ASR: Context-Aware Speaker-Attributed ASR", INTERSPEECH 2023</li>
  <li>Zhifu Gao, Zerui Li, Jiaming Wang, Haoneng Luo, Xian Shi, Mengzhe Chen, Yabin Li, Lingyun Zuo, <strong><u>Zhihao Du</u></strong>, Zhangyu Xiao, Shiliang Zhang, "FunASR: A Fundamental End-to-End Speech Recognition Toolkit", INTERSPEECH 2023</li>
  <li>Jiaming Wang*, <strong><u>Zhihao Du*</u></strong>, Shiliang Zhang. TOLD: A Novel Two-stage Overlap-aware Framework for Speaker Diarization. ICASSP 2023 (equal contribution)</li>
  <li><strong><u>Zhihao Du</u></strong>, Shiliang Zhang, Siqi Zheng, Zhijie Yan. Speaker Overlap-aware Neural Diarization for Multi-party Meeting Analysis. EMNLP 2022 (long paper)</li>
  <li>Fan Yu, Shiliang Zhang, Pengcheng Guo, Yuhao Liang, <strong><u>Zhihao Du</u></strong>, et.al. MFCCA: Multi-Frame Cross-Channel attention for multi-speaker ASR in Multi-party meeting scenario. SLT 2022</li>
  <li>Fan Yu, <strong><u>Zhihao Du</u></strong>, Shiliang Zhang, Yuxiao Lin, Lei Xie. A Comparative Study on Speaker-attributed Automatic Speech Recognition in Multi-party Meetings. ICASSP 2022</li>
  <li>Fan Yu, Shiliang Zhang, Pengcheng Guo, Yihui Fu, <strong><u>Zhihao Du</u></strong>, et.al. Summary on the ICASSP 2022 multi-channel multi-party meeting transcription grand challenge. ICASSP 2022</li>
  <li>Fan Yu, Shiliang Zhang, Yihui Fu, Lei Xie, Siqi Zheng, <strong><u>Zhihao Du</u></strong>, et.al. M2MeT: The ICASSP 2022 multi-channel multi-party meeting transcription challenge. ICASSP 2022</li>
  <li>Hongwei Song, Jiqing Han, Shiwen Deng, <strong><u>Zhihao Du</u></strong>. Capturing Temporal Dependencies Through Future Prediction for CNN-Based Audio Classifiers. ICASSP 2021</li>
  <li><strong><u>Zhihao Du</u></strong>, Ming Lei, Jiqing Han, Shiliang Zhang. Pan: Phoneme-aware network for monaural speech enhancement. ICASSP 2020.</li>
  <li><strong><u>Zhihao Du</u></strong>, Ming Lei, Jiqing Han, Shiliang Zhang. Self-Supervised Adversarial Multi-Task Learning for Vocoder-Based Monaural Speech Enhancement. INTERSPEECH 2020</li>
  <li><strong><u>Zhihao Du</u></strong>, Jiqing Han, Xueliang Zhang. Double Adversarial Network Based Monaural Speech Enhancement for Robust Speech Recognition. INTERSPEECH 2020, https://github.com/ZhihaoDU/du2020dan</li>
  <li>Yue Gu, <strong><u>Zhihao Du</u></strong>, Hui Zhang, Xueliang Zhang. An Efficient Joint Training Framework for Robust Small-Footprint Keyword Spotting. ICONIP 2020</li>
  <li>Hongwei Song, Jiqing Han, Shiwen Deng. <strong><u>Zhihao Du</u></strong>. Acoustic scene classification by implicitly identifying distinct sound events, INTERSPEECH 2019</li>
  <li><strong><u>Zhihao Du</u></strong>, Xueliang Zhang, Jiqing Han. Investigation of Monaural Front-End Processing for Robust Speech Recognition Without Retraining or Joint-Training. APSIPA 2019.</li>
</ol>
      
<h3 id="preprints">Preprints（预印本）</h3>

<ol>
  <li><strong><u>Zhihao Du</u></strong>, Shiliang Zhang, Siqi Zheng, Zhijie Yan. Speaker Embedding-aware Neural Diarization for Flexible Number of Speakers with Textual Information. https://arxiv.org/abs/2111.13694.</li>
</ol>

<h3 id="phd-thesis">PhD Thesis（博士论文）</h3>

<p>RESEARCH ON MONAURAL SPEECH ENHANCEMENT BASED ON PRIOR INFORMATION IN DIFFERENT SEMANTIC LEVELS（基于不同语义层级先验信息的
   单通道语音增强方法研究）.</p>

<h2 id="审稿">Reviewer（审稿)</h2>

<ol>
  <li>Conference of the International Speech Communication Association (INTERSPEECH) 2023</li>
  <li>International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2023</li>
  <li>International Symposium on Chinese Spoken Language Processing (ISCSLP) 2022</li>
</ol>

<h2 id="opensources">Open sources（开源代码）</h2>
<ol>
  <li>Widely-used speech features, https://github.com/ZhihaoDU/speech_feature_extractor, star 100+</li>
</ol>
  
<h2 id="荣誉">Honors（荣誉）</h2>
<ol>
  <li>哈尔滨工业大学优秀博士论文提名（2021）</li>
  <li>内蒙古自治区优秀毕业生（2015）</li>
  <li>MCM Meritorious Winner</li>
  <li>ACM/ICPC 二等奖</li>
</ol>
      
<h2 id="Organization">Organization（组织）</h2>
<ol>
  <li>IEEE Member</li>
  <li>SIGDAT Member</li>
</ol>

<h2 id="contact-me">Contact me（联系我）</h2>

<p>TEL: +86-15600609952</p>

<p>E-mails: duzhihao.china@gmail.com and neo.dzh@alibaba-inc.com.</p>

      
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.0/anchor.min.js" integrity="sha256-lZaRhKri35AyJSypXXs4o6OPFTbTmUoltBbDCbdzegg=" crossorigin="anonymous"></script>
    <script>anchors.add();</script>
  </body>
</html>

